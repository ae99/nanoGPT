{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Job 1, replicate the forward pass of a single MLP layer from GPTNeoXMLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modeling_gpt_neox import GPTNeoXForCausalLM\n",
    "model = GPTNeoXForCausalLM.from_pretrained(\"trl-internal-testing/tiny-random-GPTNeoXForCausalLM\")\n",
    "from modeling_gpt_neox import GPTNeoXMLP\n",
    "mlp = GPTNeoXMLP(model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['gpt_neox.embed_in.weight', 'gpt_neox.layers.0.input_layernorm.weight', 'gpt_neox.layers.0.input_layernorm.bias', 'gpt_neox.layers.0.post_attention_layernorm.weight', 'gpt_neox.layers.0.post_attention_layernorm.bias', 'gpt_neox.layers.0.attention.bias', 'gpt_neox.layers.0.attention.masked_bias', 'gpt_neox.layers.0.attention.rotary_emb.inv_freq', 'gpt_neox.layers.0.attention.query_key_value.weight', 'gpt_neox.layers.0.attention.query_key_value.bias', 'gpt_neox.layers.0.attention.dense.weight', 'gpt_neox.layers.0.attention.dense.bias', 'gpt_neox.layers.0.mlp.dense_h_to_4h.weight', 'gpt_neox.layers.0.mlp.dense_h_to_4h.bias', 'gpt_neox.layers.0.mlp.dense_4h_to_h.weight', 'gpt_neox.layers.0.mlp.dense_4h_to_h.bias', 'gpt_neox.layers.1.input_layernorm.weight', 'gpt_neox.layers.1.input_layernorm.bias', 'gpt_neox.layers.1.post_attention_layernorm.weight', 'gpt_neox.layers.1.post_attention_layernorm.bias', 'gpt_neox.layers.1.attention.bias', 'gpt_neox.layers.1.attention.masked_bias', 'gpt_neox.layers.1.attention.rotary_emb.inv_freq', 'gpt_neox.layers.1.attention.query_key_value.weight', 'gpt_neox.layers.1.attention.query_key_value.bias', 'gpt_neox.layers.1.attention.dense.weight', 'gpt_neox.layers.1.attention.dense.bias', 'gpt_neox.layers.1.mlp.dense_h_to_4h.weight', 'gpt_neox.layers.1.mlp.dense_h_to_4h.bias', 'gpt_neox.layers.1.mlp.dense_4h_to_h.weight', 'gpt_neox.layers.1.mlp.dense_4h_to_h.bias', 'gpt_neox.layers.2.input_layernorm.weight', 'gpt_neox.layers.2.input_layernorm.bias', 'gpt_neox.layers.2.post_attention_layernorm.weight', 'gpt_neox.layers.2.post_attention_layernorm.bias', 'gpt_neox.layers.2.attention.bias', 'gpt_neox.layers.2.attention.masked_bias', 'gpt_neox.layers.2.attention.rotary_emb.inv_freq', 'gpt_neox.layers.2.attention.query_key_value.weight', 'gpt_neox.layers.2.attention.query_key_value.bias', 'gpt_neox.layers.2.attention.dense.weight', 'gpt_neox.layers.2.attention.dense.bias', 'gpt_neox.layers.2.mlp.dense_h_to_4h.weight', 'gpt_neox.layers.2.mlp.dense_h_to_4h.bias', 'gpt_neox.layers.2.mlp.dense_4h_to_h.weight', 'gpt_neox.layers.2.mlp.dense_4h_to_h.bias', 'gpt_neox.layers.3.input_layernorm.weight', 'gpt_neox.layers.3.input_layernorm.bias', 'gpt_neox.layers.3.post_attention_layernorm.weight', 'gpt_neox.layers.3.post_attention_layernorm.bias', 'gpt_neox.layers.3.attention.bias', 'gpt_neox.layers.3.attention.masked_bias', 'gpt_neox.layers.3.attention.rotary_emb.inv_freq', 'gpt_neox.layers.3.attention.query_key_value.weight', 'gpt_neox.layers.3.attention.query_key_value.bias', 'gpt_neox.layers.3.attention.dense.weight', 'gpt_neox.layers.3.attention.dense.bias', 'gpt_neox.layers.3.mlp.dense_h_to_4h.weight', 'gpt_neox.layers.3.mlp.dense_h_to_4h.bias', 'gpt_neox.layers.3.mlp.dense_4h_to_h.weight', 'gpt_neox.layers.3.mlp.dense_4h_to_h.bias', 'gpt_neox.layers.4.input_layernorm.weight', 'gpt_neox.layers.4.input_layernorm.bias', 'gpt_neox.layers.4.post_attention_layernorm.weight', 'gpt_neox.layers.4.post_attention_layernorm.bias', 'gpt_neox.layers.4.attention.bias', 'gpt_neox.layers.4.attention.masked_bias', 'gpt_neox.layers.4.attention.rotary_emb.inv_freq', 'gpt_neox.layers.4.attention.query_key_value.weight', 'gpt_neox.layers.4.attention.query_key_value.bias', 'gpt_neox.layers.4.attention.dense.weight', 'gpt_neox.layers.4.attention.dense.bias', 'gpt_neox.layers.4.mlp.dense_h_to_4h.weight', 'gpt_neox.layers.4.mlp.dense_h_to_4h.bias', 'gpt_neox.layers.4.mlp.dense_4h_to_h.weight', 'gpt_neox.layers.4.mlp.dense_4h_to_h.bias', 'gpt_neox.final_layer_norm.weight', 'gpt_neox.final_layer_norm.bias', 'embed_out.weight'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict().keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('dense_h_to_4h.weight',\n",
       "              tensor([[-0.0196, -0.0990,  0.0053,  ..., -0.1003,  0.0830, -0.1078],\n",
       "                      [-0.1272,  0.0624,  0.0038,  ...,  0.0646, -0.1679,  0.0583],\n",
       "                      [-0.1134,  0.1146, -0.0012,  ...,  0.0271, -0.1597, -0.0135],\n",
       "                      ...,\n",
       "                      [-0.0126,  0.1699,  0.0780,  ..., -0.0070,  0.0816,  0.0627],\n",
       "                      [-0.1656,  0.0370,  0.0644,  ..., -0.1699,  0.0368,  0.1037],\n",
       "                      [-0.0942, -0.0225,  0.1011,  ...,  0.0172,  0.1001,  0.0858]])),\n",
       "             ('dense_h_to_4h.bias',\n",
       "              tensor([ 0.0530, -0.0849, -0.0423, -0.0756,  0.0913, -0.0701, -0.0461,  0.1709,\n",
       "                       0.1040, -0.0970,  0.1308, -0.0084,  0.0234, -0.1548,  0.0129, -0.1482,\n",
       "                      -0.1448, -0.1171, -0.0652,  0.0490, -0.1079, -0.0694, -0.0493, -0.0803,\n",
       "                      -0.1245,  0.0244, -0.0565,  0.1330,  0.1505,  0.0260, -0.1201,  0.0481,\n",
       "                      -0.1755, -0.1004, -0.1226, -0.1210,  0.0383])),\n",
       "             ('dense_4h_to_h.weight',\n",
       "              tensor([[ 0.1190, -0.0936, -0.0338,  ...,  0.1338,  0.0636,  0.1509],\n",
       "                      [-0.0048, -0.1057,  0.0044,  ...,  0.1572,  0.1177, -0.0910],\n",
       "                      [-0.1315,  0.1283, -0.0637,  ...,  0.0664, -0.0861, -0.0410],\n",
       "                      ...,\n",
       "                      [-0.0569,  0.0868, -0.0970,  ...,  0.0207,  0.0521,  0.0704],\n",
       "                      [ 0.0557,  0.0877,  0.1327,  ..., -0.1480,  0.0072, -0.1507],\n",
       "                      [ 0.1071, -0.1353,  0.1178,  ...,  0.0269, -0.0137, -0.0892]])),\n",
       "             ('dense_4h_to_h.bias',\n",
       "              tensor([-0.1413, -0.1438,  0.1519,  0.1289, -0.1350,  0.0505,  0.1123,  0.0043,\n",
       "                       0.0233, -0.0029, -0.0851, -0.1308,  0.0930,  0.0879, -0.0472, -0.0797,\n",
       "                       0.1394,  0.0513,  0.1617, -0.1536, -0.1004,  0.1099,  0.1317,  0.1226,\n",
       "                       0.1474,  0.1140,  0.0950,  0.0090, -0.1128,  0.0076, -0.1396,  0.0373]))])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename the keys to match the mlp\n",
    "new_state_dict = {}\n",
    "for k, v in model.state_dict().items():\n",
    "    if k.startswith(\"gpt_neox.layers.1.mlp.\"):\n",
    "        new_state_dict[k.replace(\"gpt_neox.layers.1.mlp.\", \"\")] = v\n",
    "\n",
    "mlp.load_state_dict(new_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.8557e-03, -7.1405e-03,  7.3479e-04,  1.7308e-03,  1.0328e-02,\n",
       "          5.5924e-03,  1.7156e-03,  8.4459e-03,  8.2332e-03,  3.5740e-03,\n",
       "         -8.4398e-04, -3.7490e-03, -2.2467e-03,  5.3495e-03, -3.3868e-03,\n",
       "         -5.4625e-04,  3.0698e-03, -2.8900e-03, -4.0124e-05, -7.1420e-03,\n",
       "         -3.3980e-03, -4.9446e-03, -3.6563e-03,  8.5901e-03, -5.9791e-03,\n",
       "         -2.1923e-03, -1.7515e-03,  3.2583e-03,  9.8841e-03, -3.3359e-03,\n",
       "          8.8847e-04, -7.3157e-03],\n",
       "        [ 7.6398e-03,  5.2383e-03,  9.7130e-04,  6.1106e-03, -6.8673e-03,\n",
       "          4.9993e-03, -1.7223e-03,  6.2101e-03, -7.9022e-03,  1.0678e-02,\n",
       "          2.7250e-03, -1.6588e-03,  2.5691e-03,  3.7006e-03, -4.1308e-03,\n",
       "          2.5991e-03, -3.5686e-03,  2.0885e-03, -4.1439e-03,  8.7240e-03,\n",
       "         -1.2532e-03,  4.4078e-03,  6.3213e-03,  4.7644e-03, -2.6624e-03,\n",
       "          4.8762e-03, -6.2065e-03,  3.4692e-03, -8.7608e-03,  2.0760e-03,\n",
       "          7.4033e-04, -7.3633e-03]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "inputState = torch.randn(2, 32)\n",
    "mlp(inputState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.c_fc    = nn.Linear(config.hidden_size, config.intermediate_size, bias=True) # n_embd, 4 * n_embd\n",
    "        self.c_proj  = nn.Linear(config.intermediate_size, config.hidden_size, bias=True)\n",
    "        self.dropout = nn.Dropout(0) # no dropout\n",
    "        self.act = torch.nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.c_fc(x)\n",
    "        x = self.act(x)\n",
    "        x = self.c_proj(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "mlp2 = MLP(model.config)\n",
    "new_state_dict = {\n",
    "    \"c_fc.weight\": model.state_dict()[\"gpt_neox.layers.1.mlp.dense_h_to_4h.weight\"],\n",
    "    \"c_fc.bias\": model.state_dict()[\"gpt_neox.layers.1.mlp.dense_h_to_4h.bias\"],\n",
    "    \"c_proj.weight\": model.state_dict()[\"gpt_neox.layers.1.mlp.dense_4h_to_h.weight\"],\n",
    "    \"c_proj.bias\": model.state_dict()[\"gpt_neox.layers.1.mlp.dense_4h_to_h.bias\"],\n",
    "}\n",
    "mlp2.load_state_dict(new_state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-4.8557e-03, -7.1405e-03,  7.3479e-04,  1.7308e-03,  1.0328e-02,\n",
       "           5.5924e-03,  1.7156e-03,  8.4459e-03,  8.2332e-03,  3.5740e-03,\n",
       "          -8.4398e-04, -3.7490e-03, -2.2467e-03,  5.3495e-03, -3.3868e-03,\n",
       "          -5.4625e-04,  3.0698e-03, -2.8900e-03, -4.0124e-05, -7.1420e-03,\n",
       "          -3.3980e-03, -4.9446e-03, -3.6563e-03,  8.5901e-03, -5.9791e-03,\n",
       "          -2.1923e-03, -1.7515e-03,  3.2583e-03,  9.8841e-03, -3.3359e-03,\n",
       "           8.8847e-04, -7.3157e-03],\n",
       "         [ 7.6398e-03,  5.2383e-03,  9.7130e-04,  6.1106e-03, -6.8673e-03,\n",
       "           4.9993e-03, -1.7223e-03,  6.2101e-03, -7.9022e-03,  1.0678e-02,\n",
       "           2.7250e-03, -1.6588e-03,  2.5691e-03,  3.7006e-03, -4.1308e-03,\n",
       "           2.5991e-03, -3.5686e-03,  2.0885e-03, -4.1439e-03,  8.7240e-03,\n",
       "          -1.2532e-03,  4.4078e-03,  6.3213e-03,  4.7644e-03, -2.6624e-03,\n",
       "           4.8762e-03, -6.2065e-03,  3.4692e-03, -8.7608e-03,  2.0760e-03,\n",
       "           7.4033e-04, -7.3633e-03]], grad_fn=<AddmmBackward0>),\n",
       " tensor([[-4.8557e-03, -7.1405e-03,  7.3479e-04,  1.7308e-03,  1.0328e-02,\n",
       "           5.5924e-03,  1.7156e-03,  8.4459e-03,  8.2332e-03,  3.5740e-03,\n",
       "          -8.4398e-04, -3.7490e-03, -2.2467e-03,  5.3495e-03, -3.3868e-03,\n",
       "          -5.4625e-04,  3.0698e-03, -2.8900e-03, -4.0124e-05, -7.1420e-03,\n",
       "          -3.3980e-03, -4.9446e-03, -3.6563e-03,  8.5901e-03, -5.9791e-03,\n",
       "          -2.1923e-03, -1.7515e-03,  3.2583e-03,  9.8841e-03, -3.3359e-03,\n",
       "           8.8847e-04, -7.3157e-03],\n",
       "         [ 7.6398e-03,  5.2383e-03,  9.7130e-04,  6.1106e-03, -6.8673e-03,\n",
       "           4.9993e-03, -1.7223e-03,  6.2101e-03, -7.9022e-03,  1.0678e-02,\n",
       "           2.7250e-03, -1.6588e-03,  2.5691e-03,  3.7006e-03, -4.1308e-03,\n",
       "           2.5991e-03, -3.5686e-03,  2.0885e-03, -4.1439e-03,  8.7240e-03,\n",
       "          -1.2532e-03,  4.4078e-03,  6.3213e-03,  4.7644e-03, -2.6624e-03,\n",
       "           4.8762e-03, -6.2065e-03,  3.4692e-03, -8.7608e-03,  2.0760e-03,\n",
       "           7.4033e-04, -7.3633e-03]], grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp2(inputState), mlp(inputState)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# check that the two mlp's are the same\n",
    "torch.allclose(mlp2(inputState), mlp(inputState))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b66dbdb614bfd022b649975f993762ad232399f75e8f30cb9176d485ed5b8487"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
