{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Job 1, replicate the forward pass of a single MLP layer from GPTNeoXMLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modeling_gpt_neox import GPTNeoXForCausalLM\n",
    "model = GPTNeoXForCausalLM.from_pretrained(\"trl-internal-testing/tiny-random-GPTNeoXForCausalLM\")\n",
    "from modeling_gpt_neox import GPTNeoXMLP\n",
    "mlp = GPTNeoXMLP(model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['gpt_neox.embed_in.weight', 'gpt_neox.layers.0.input_layernorm.weight', 'gpt_neox.layers.0.input_layernorm.bias', 'gpt_neox.layers.0.post_attention_layernorm.weight', 'gpt_neox.layers.0.post_attention_layernorm.bias', 'gpt_neox.layers.0.attention.bias', 'gpt_neox.layers.0.attention.masked_bias', 'gpt_neox.layers.0.attention.rotary_emb.inv_freq', 'gpt_neox.layers.0.attention.query_key_value.weight', 'gpt_neox.layers.0.attention.query_key_value.bias', 'gpt_neox.layers.0.attention.dense.weight', 'gpt_neox.layers.0.attention.dense.bias', 'gpt_neox.layers.0.mlp.dense_h_to_4h.weight', 'gpt_neox.layers.0.mlp.dense_h_to_4h.bias', 'gpt_neox.layers.0.mlp.dense_4h_to_h.weight', 'gpt_neox.layers.0.mlp.dense_4h_to_h.bias', 'gpt_neox.layers.1.input_layernorm.weight', 'gpt_neox.layers.1.input_layernorm.bias', 'gpt_neox.layers.1.post_attention_layernorm.weight', 'gpt_neox.layers.1.post_attention_layernorm.bias', 'gpt_neox.layers.1.attention.bias', 'gpt_neox.layers.1.attention.masked_bias', 'gpt_neox.layers.1.attention.rotary_emb.inv_freq', 'gpt_neox.layers.1.attention.query_key_value.weight', 'gpt_neox.layers.1.attention.query_key_value.bias', 'gpt_neox.layers.1.attention.dense.weight', 'gpt_neox.layers.1.attention.dense.bias', 'gpt_neox.layers.1.mlp.dense_h_to_4h.weight', 'gpt_neox.layers.1.mlp.dense_h_to_4h.bias', 'gpt_neox.layers.1.mlp.dense_4h_to_h.weight', 'gpt_neox.layers.1.mlp.dense_4h_to_h.bias', 'gpt_neox.layers.2.input_layernorm.weight', 'gpt_neox.layers.2.input_layernorm.bias', 'gpt_neox.layers.2.post_attention_layernorm.weight', 'gpt_neox.layers.2.post_attention_layernorm.bias', 'gpt_neox.layers.2.attention.bias', 'gpt_neox.layers.2.attention.masked_bias', 'gpt_neox.layers.2.attention.rotary_emb.inv_freq', 'gpt_neox.layers.2.attention.query_key_value.weight', 'gpt_neox.layers.2.attention.query_key_value.bias', 'gpt_neox.layers.2.attention.dense.weight', 'gpt_neox.layers.2.attention.dense.bias', 'gpt_neox.layers.2.mlp.dense_h_to_4h.weight', 'gpt_neox.layers.2.mlp.dense_h_to_4h.bias', 'gpt_neox.layers.2.mlp.dense_4h_to_h.weight', 'gpt_neox.layers.2.mlp.dense_4h_to_h.bias', 'gpt_neox.layers.3.input_layernorm.weight', 'gpt_neox.layers.3.input_layernorm.bias', 'gpt_neox.layers.3.post_attention_layernorm.weight', 'gpt_neox.layers.3.post_attention_layernorm.bias', 'gpt_neox.layers.3.attention.bias', 'gpt_neox.layers.3.attention.masked_bias', 'gpt_neox.layers.3.attention.rotary_emb.inv_freq', 'gpt_neox.layers.3.attention.query_key_value.weight', 'gpt_neox.layers.3.attention.query_key_value.bias', 'gpt_neox.layers.3.attention.dense.weight', 'gpt_neox.layers.3.attention.dense.bias', 'gpt_neox.layers.3.mlp.dense_h_to_4h.weight', 'gpt_neox.layers.3.mlp.dense_h_to_4h.bias', 'gpt_neox.layers.3.mlp.dense_4h_to_h.weight', 'gpt_neox.layers.3.mlp.dense_4h_to_h.bias', 'gpt_neox.layers.4.input_layernorm.weight', 'gpt_neox.layers.4.input_layernorm.bias', 'gpt_neox.layers.4.post_attention_layernorm.weight', 'gpt_neox.layers.4.post_attention_layernorm.bias', 'gpt_neox.layers.4.attention.bias', 'gpt_neox.layers.4.attention.masked_bias', 'gpt_neox.layers.4.attention.rotary_emb.inv_freq', 'gpt_neox.layers.4.attention.query_key_value.weight', 'gpt_neox.layers.4.attention.query_key_value.bias', 'gpt_neox.layers.4.attention.dense.weight', 'gpt_neox.layers.4.attention.dense.bias', 'gpt_neox.layers.4.mlp.dense_h_to_4h.weight', 'gpt_neox.layers.4.mlp.dense_h_to_4h.bias', 'gpt_neox.layers.4.mlp.dense_4h_to_h.weight', 'gpt_neox.layers.4.mlp.dense_4h_to_h.bias', 'gpt_neox.final_layer_norm.weight', 'gpt_neox.final_layer_norm.bias', 'embed_out.weight'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('dense_h_to_4h.weight',\n",
       "              tensor([[-0.1292,  0.0443, -0.0774,  ...,  0.1287,  0.0994,  0.1353],\n",
       "                      [-0.0972,  0.0236,  0.0603,  ..., -0.0110,  0.1672, -0.0086],\n",
       "                      [-0.1191,  0.1188, -0.0998,  ...,  0.1715, -0.0931,  0.0332],\n",
       "                      ...,\n",
       "                      [-0.1726, -0.1050,  0.0902,  ...,  0.0563,  0.0638, -0.1391],\n",
       "                      [ 0.1363, -0.1630, -0.1528,  ...,  0.1118, -0.1547, -0.0386],\n",
       "                      [-0.1348,  0.0011,  0.0667,  ..., -0.1358, -0.0009,  0.0612]])),\n",
       "             ('dense_h_to_4h.bias',\n",
       "              tensor([-0.1660, -0.0538, -0.0403,  0.1558, -0.1458, -0.1026,  0.0619, -0.0821,\n",
       "                      -0.0827, -0.0799, -0.0938, -0.1722,  0.1314,  0.0845, -0.0783,  0.0237,\n",
       "                       0.1370,  0.0882, -0.0298, -0.0890,  0.1016, -0.1717,  0.1479, -0.0651,\n",
       "                      -0.0814, -0.1165, -0.0256,  0.0875, -0.0698,  0.0542,  0.0200,  0.1422,\n",
       "                      -0.0330, -0.0419,  0.1462, -0.0133, -0.1518])),\n",
       "             ('dense_4h_to_h.weight',\n",
       "              tensor([[-0.0295,  0.0084,  0.1087,  ...,  0.0273, -0.0386, -0.1586],\n",
       "                      [ 0.0249, -0.0245, -0.1312,  ...,  0.1462, -0.1492, -0.1048],\n",
       "                      [-0.0922, -0.0577,  0.1620,  ..., -0.0421, -0.0714, -0.0024],\n",
       "                      ...,\n",
       "                      [-0.0394,  0.0795, -0.0147,  ..., -0.0030,  0.1100,  0.0031],\n",
       "                      [-0.0704,  0.1417, -0.0652,  ...,  0.1403,  0.0605, -0.1125],\n",
       "                      [ 0.0763,  0.0284,  0.0402,  ..., -0.1021,  0.0514,  0.0034]])),\n",
       "             ('dense_4h_to_h.bias',\n",
       "              tensor([-0.0461, -0.1562, -0.0857,  0.1474,  0.1634, -0.0223, -0.1442, -0.0384,\n",
       "                       0.0680,  0.0955, -0.1181,  0.1554, -0.0318,  0.1397, -0.0179, -0.1352,\n",
       "                      -0.0738, -0.0321,  0.0214,  0.0852,  0.0982,  0.0778, -0.1363, -0.0455,\n",
       "                       0.1562,  0.0874,  0.0379, -0.1180, -0.1429,  0.0103, -0.0709, -0.0275]))])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename the keys to match the mlp\n",
    "new_state_dict = {}\n",
    "for k, v in model.state_dict().items():\n",
    "    if k.startswith(\"gpt_neox.layers.1.mlp.\"):\n",
    "        new_state_dict[k.replace(\"gpt_neox.layers.1.mlp.\", \"\")] = v\n",
    "\n",
    "mlp.load_state_dict(new_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.8557e-03, -7.1405e-03,  7.3479e-04,  1.7308e-03,  1.0328e-02,\n",
       "          5.5924e-03,  1.7156e-03,  8.4459e-03,  8.2332e-03,  3.5740e-03,\n",
       "         -8.4398e-04, -3.7490e-03, -2.2467e-03,  5.3495e-03, -3.3868e-03,\n",
       "         -5.4625e-04,  3.0698e-03, -2.8900e-03, -4.0124e-05, -7.1420e-03,\n",
       "         -3.3980e-03, -4.9446e-03, -3.6563e-03,  8.5901e-03, -5.9791e-03,\n",
       "         -2.1923e-03, -1.7515e-03,  3.2583e-03,  9.8841e-03, -3.3359e-03,\n",
       "          8.8847e-04, -7.3157e-03],\n",
       "        [ 7.6398e-03,  5.2383e-03,  9.7130e-04,  6.1106e-03, -6.8673e-03,\n",
       "          4.9993e-03, -1.7223e-03,  6.2101e-03, -7.9022e-03,  1.0678e-02,\n",
       "          2.7250e-03, -1.6588e-03,  2.5691e-03,  3.7006e-03, -4.1308e-03,\n",
       "          2.5991e-03, -3.5686e-03,  2.0885e-03, -4.1439e-03,  8.7240e-03,\n",
       "         -1.2532e-03,  4.4078e-03,  6.3213e-03,  4.7644e-03, -2.6624e-03,\n",
       "          4.8762e-03, -6.2065e-03,  3.4692e-03, -8.7608e-03,  2.0760e-03,\n",
       "          7.4033e-04, -7.3633e-03]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "inputState = torch.randn(2, 32)\n",
    "mlp(inputState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.c_fc    = nn.Linear(config.hidden_size, config.intermediate_size, bias=True) # n_embd, 4 * n_embd\n",
    "        self.c_proj  = nn.Linear(config.intermediate_size, config.hidden_size, bias=True)\n",
    "        self.dropout = nn.Dropout(0) # no dropout\n",
    "        self.act = torch.nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.c_fc(x)\n",
    "        x = self.act(x)\n",
    "        x = self.c_proj(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "mlp2 = MLP(model.config)\n",
    "new_state_dict = {\n",
    "    \"c_fc.weight\": model.state_dict()[\"gpt_neox.layers.1.mlp.dense_h_to_4h.weight\"],\n",
    "    \"c_fc.bias\": model.state_dict()[\"gpt_neox.layers.1.mlp.dense_h_to_4h.bias\"],\n",
    "    \"c_proj.weight\": model.state_dict()[\"gpt_neox.layers.1.mlp.dense_4h_to_h.weight\"],\n",
    "    \"c_proj.bias\": model.state_dict()[\"gpt_neox.layers.1.mlp.dense_4h_to_h.bias\"],\n",
    "}\n",
    "mlp2.load_state_dict(new_state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-4.8557e-03, -7.1405e-03,  7.3479e-04,  1.7308e-03,  1.0328e-02,\n",
       "           5.5924e-03,  1.7156e-03,  8.4459e-03,  8.2332e-03,  3.5740e-03,\n",
       "          -8.4398e-04, -3.7490e-03, -2.2467e-03,  5.3495e-03, -3.3868e-03,\n",
       "          -5.4625e-04,  3.0698e-03, -2.8900e-03, -4.0124e-05, -7.1420e-03,\n",
       "          -3.3980e-03, -4.9446e-03, -3.6563e-03,  8.5901e-03, -5.9791e-03,\n",
       "          -2.1923e-03, -1.7515e-03,  3.2583e-03,  9.8841e-03, -3.3359e-03,\n",
       "           8.8847e-04, -7.3157e-03],\n",
       "         [ 7.6398e-03,  5.2383e-03,  9.7130e-04,  6.1106e-03, -6.8673e-03,\n",
       "           4.9993e-03, -1.7223e-03,  6.2101e-03, -7.9022e-03,  1.0678e-02,\n",
       "           2.7250e-03, -1.6588e-03,  2.5691e-03,  3.7006e-03, -4.1308e-03,\n",
       "           2.5991e-03, -3.5686e-03,  2.0885e-03, -4.1439e-03,  8.7240e-03,\n",
       "          -1.2532e-03,  4.4078e-03,  6.3213e-03,  4.7644e-03, -2.6624e-03,\n",
       "           4.8762e-03, -6.2065e-03,  3.4692e-03, -8.7608e-03,  2.0760e-03,\n",
       "           7.4033e-04, -7.3633e-03]], grad_fn=<AddmmBackward0>),\n",
       " tensor([[-4.8557e-03, -7.1405e-03,  7.3479e-04,  1.7308e-03,  1.0328e-02,\n",
       "           5.5924e-03,  1.7156e-03,  8.4459e-03,  8.2332e-03,  3.5740e-03,\n",
       "          -8.4398e-04, -3.7490e-03, -2.2467e-03,  5.3495e-03, -3.3868e-03,\n",
       "          -5.4625e-04,  3.0698e-03, -2.8900e-03, -4.0124e-05, -7.1420e-03,\n",
       "          -3.3980e-03, -4.9446e-03, -3.6563e-03,  8.5901e-03, -5.9791e-03,\n",
       "          -2.1923e-03, -1.7515e-03,  3.2583e-03,  9.8841e-03, -3.3359e-03,\n",
       "           8.8847e-04, -7.3157e-03],\n",
       "         [ 7.6398e-03,  5.2383e-03,  9.7130e-04,  6.1106e-03, -6.8673e-03,\n",
       "           4.9993e-03, -1.7223e-03,  6.2101e-03, -7.9022e-03,  1.0678e-02,\n",
       "           2.7250e-03, -1.6588e-03,  2.5691e-03,  3.7006e-03, -4.1308e-03,\n",
       "           2.5991e-03, -3.5686e-03,  2.0885e-03, -4.1439e-03,  8.7240e-03,\n",
       "          -1.2532e-03,  4.4078e-03,  6.3213e-03,  4.7644e-03, -2.6624e-03,\n",
       "           4.8762e-03, -6.2065e-03,  3.4692e-03, -8.7608e-03,  2.0760e-03,\n",
       "           7.4033e-04, -7.3633e-03]], grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp2(inputState), mlp(inputState)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# check that the two mlp's are the same\n",
    "torch.allclose(mlp2(inputState), mlp(inputState))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b66dbdb614bfd022b649975f993762ad232399f75e8f30cb9176d485ed5b8487"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
