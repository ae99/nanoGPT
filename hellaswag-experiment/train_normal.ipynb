{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights from pretrained GPTNeoX: EleutherAI/pythia-70m\n",
      "WARNING: using slow attention. Flash Attention atm needs PyTorch nightly and dropout=0.0\n",
      "WARNING: using slow attention. Flash Attention atm needs PyTorch nightly and dropout=0.0\n",
      "WARNING: using slow attention. Flash Attention atm needs PyTorch nightly and dropout=0.0\n",
      "WARNING: using slow attention. Flash Attention atm needs PyTorch nightly and dropout=0.0\n",
      "WARNING: using slow attention. Flash Attention atm needs PyTorch nightly and dropout=0.0\n",
      "WARNING: using slow attention. Flash Attention atm needs PyTorch nightly and dropout=0.0\n",
      "number of parameters: 70.43M\n"
     ]
    }
   ],
   "source": [
    "# Init modeo\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path('./train_normal.ipynb').resolve().parent.parent))\n",
    "\n",
    "from model import GPT\n",
    "from transformers import GPTNeoXTokenizerFast\n",
    "model = GPT.from_pretrained('EleutherAI/pythia-70m')\n",
    "tokenizer = GPTNeoXTokenizerFast.from_pretrained('EleutherAI/pythia-70m')\n",
    "tokenizer.add_tokens(['<|dense|>'])\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "dense_token_id = tokenizer.encode('<|dense|>')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from load_data import train, val, process_example, example_to_text\n",
    "\n",
    "def tokenize_data(data):\n",
    "    tokenized_data = []\n",
    "    for example in data:\n",
    "        processed_example = process_example(example)\n",
    "        example_text = example_to_text(processed_example)\n",
    "        \n",
    "        tokens = tokenizer.encode(example_text, return_tensors='pt', max_length=512, truncation=True)\n",
    "        \n",
    "        tokenized_data.append({\n",
    "            'tokens': tokens,\n",
    "        })\n",
    "    return tokenized_data\n",
    "\n",
    "\n",
    "train_data = tokenize_data(train)\n",
    "val_data = tokenize_data(val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39905, 10042)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(val)\n",
    "# 64, 16\n",
    "# 623 times larger\n",
    "# 623 * 4.5s = 2803s = 47 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class HellaSwagDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        return {\n",
    "            'input_ids': item['tokens'],\n",
    "            'length': item['tokens'].shape[1],\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "train_dataset = HellaSwagDataset(train_data)\n",
    "val_dataset = HellaSwagDataset(val_data)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    input_ids = [item['input_ids'].squeeze(0) for item in batch]\n",
    "    input_ids = tokenizer.pad({\"input_ids\": input_ids}, return_tensors='pt')['input_ids']\n",
    "\n",
    "    label_index = torch.tensor([item['length'] for item in batch])\n",
    "\n",
    "    return {\n",
    "        'input_ids': input_ids.contiguous(),\n",
    "        'label_index': label_index.contiguous(),\n",
    "    }\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# we're going to end up with a function that can show both validation and training accuracy too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(Y, label_index, logits, doPrint=False):\n",
    "    label_index = label_index -2\n",
    "    correct = 0\n",
    "    for i in range(Y.shape[0]):\n",
    "        expected = tokenizer.decode(Y[i][label_index[i]])\n",
    "        recieved = tokenizer.decode(logits[i][label_index[i]].argmax(dim=-1))\n",
    "        \n",
    "        if doPrint:\n",
    "            print(expected.__repr__(), \"->\", recieved.__repr__())\n",
    "                    \n",
    "        if expected == recieved:\n",
    "            correct += 1\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPTNeoXTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using fused AdamW: False\n",
      "Training Epoch 0\n",
      "Train 0 / 16 5.279565811157227\n",
      "Train 1 / 16 4.535447597503662\n",
      "Train 0 / 16 6.316530227661133\n",
      "Train 1 / 16 5.514731407165527\n",
      "Train 0 / 16 4.835117816925049\n",
      "Train 0 / 16 4.42872953414917\n",
      "Train 0 / 16 4.118356227874756\n",
      "Train 4 / 16 4.431439399719238\n",
      "Train 2 / 16 3.9854283332824707\n",
      "Train 4 / 16 3.562023878097534\n",
      "Train 3 / 16 3.300297498703003\n",
      "Train 3 / 16 3.5383739471435547\n",
      "Train 5 / 16 3.6128053665161133\n",
      "Train 2 / 16 3.66767954826355\n",
      "Train 4 / 16 4.012118339538574\n",
      "Train 9 / 16 3.6377341747283936\n",
      "Train 3 / 16 3.364621162414551\n",
      "Train 2 / 16 3.4047317504882812\n",
      "Train 7 / 16 3.354626178741455\n",
      "Train 5 / 16 3.516059637069702\n",
      "Train 4 / 16 3.128873586654663\n",
      "Train 0 / 16 3.0958361625671387\n",
      "Train 3 / 16 3.2147557735443115\n",
      "Train 5 / 16 3.7532031536102295\n",
      "Train 2 / 16 3.372769832611084\n",
      "Train 3 / 16 3.1321141719818115\n",
      "Train 5 / 16 2.539485454559326\n",
      "Train 2 / 16 3.3538818359375\n",
      "Train 5 / 16 3.629117488861084\n",
      "Train 4 / 16 2.846911907196045\n",
      "Train 2 / 16 2.7466068267822266\n",
      "Train 5 / 16 3.3083136081695557\n",
      "Train 6 / 16 2.941171407699585\n",
      "Train 5 / 16 3.2983689308166504\n",
      "Train 3 / 16 2.925853967666626\n",
      "Train 2 / 16 3.411921977996826\n",
      "Train 5 / 16 2.6854121685028076\n",
      "Train 7 / 16 3.065606117248535\n",
      "Train 2 / 16 2.9675941467285156\n",
      "Train 6 / 16 2.4541103839874268\n",
      "Train 7 / 16 2.6348323822021484\n",
      "Train 4 / 16 2.758352756500244\n",
      "Train 1 / 16 2.897082567214966\n",
      "Train 4 / 16 2.8731822967529297\n",
      "Train 2 / 16 3.019967794418335\n",
      "Train 4 / 16 3.39382266998291\n",
      "Train 3 / 16 2.545402765274048\n",
      "Train 7 / 16 2.980489492416382\n",
      "Train 3 / 16 2.6600406169891357\n",
      "Train 4 / 16 2.6469290256500244\n",
      "Train 6 / 16 3.1099696159362793\n",
      "Train 3 / 16 2.5347981452941895\n",
      "Train 3 / 16 2.4522154331207275\n",
      "Train 4 / 16 2.8596205711364746\n",
      "Train 7 / 16 2.2849528789520264\n",
      "Train 5 / 16 2.6841931343078613\n",
      "Train 2 / 16 2.785538673400879\n",
      "Train 7 / 16 2.8207130432128906\n",
      "Train 2 / 16 2.63497257232666\n",
      "Train 6 / 16 3.000261068344116\n",
      "Train 2 / 16 2.3635969161987305\n",
      "Train 4 / 16 2.5448317527770996\n",
      "Train 3 / 16 2.295137405395508\n",
      "Train 3 / 16 2.7505064010620117\n",
      "Train 2 / 16 2.630171298980713\n",
      "Train 7 / 16 2.67525315284729\n",
      "Train 4 / 16 2.800168752670288\n",
      "Train 5 / 16 2.8254928588867188\n",
      "Train 4 / 16 2.7678682804107666\n",
      "Train 0 / 16 3.291701078414917\n",
      "Train 4 / 16 2.7977473735809326\n",
      "Train 1 / 16 2.3780484199523926\n",
      "Train 2 / 16 3.2462480068206787\n",
      "Train 1 / 16 2.385957956314087\n",
      "Train 6 / 16 2.343336343765259\n",
      "Train 7 / 16 2.9237005710601807\n",
      "Train 4 / 16 2.4674935340881348\n",
      "Train 5 / 16 2.871753215789795\n",
      "Train 3 / 16 3.151228666305542\n",
      "Train 7 / 16 2.722914457321167\n",
      "Train 4 / 16 2.425550937652588\n",
      "Train 5 / 16 2.55500864982605\n",
      "Train 6 / 16 2.661384344100952\n",
      "Train 5 / 16 2.7212107181549072\n",
      "Train 6 / 16 2.600782871246338\n",
      "Train 2 / 16 2.7305760383605957\n",
      "Train 2 / 16 2.6891286373138428\n",
      "Train 6 / 16 2.8649544715881348\n",
      "Train 6 / 16 2.493407726287842\n",
      "Train 7 / 16 2.6932976245880127\n",
      "Train 4 / 16 2.624788999557495\n",
      "Train 3 / 16 2.383354425430298\n",
      "Train 7 / 16 2.6945457458496094\n",
      "Train 5 / 16 2.789085865020752\n",
      "Train 7 / 16 2.5059814453125\n",
      "Train 3 / 16 2.8600051403045654\n",
      "Train 6 / 16 2.6020712852478027\n",
      "Train 2 / 16 2.6717429161071777\n",
      "Train 5 / 16 2.1829137802124023\n",
      "Train 3 / 16 2.385038375854492\n",
      "Train 5 / 16 2.7347192764282227\n",
      "Train 2 / 16 2.7397303581237793\n",
      "Train 6 / 16 2.188882350921631\n",
      "Train 5 / 16 2.1116485595703125\n",
      "Train 4 / 16 1.9554651975631714\n",
      "Train 3 / 16 2.6676347255706787\n",
      "Train 4 / 16 2.6396424770355225\n",
      "Train 4 / 16 2.6417698860168457\n",
      "Train 2 / 16 2.778642416000366\n",
      "Train 5 / 16 2.3093855381011963\n",
      "Train 6 / 16 2.4044764041900635\n",
      "Train 2 / 16 2.5859363079071045\n",
      "Train 3 / 16 2.911879062652588\n",
      "Train 2 / 16 2.643097400665283\n",
      "Train 2 / 16 1.8937115669250488\n",
      "Train 2 / 16 2.2625653743743896\n",
      "Train 3 / 16 2.7034709453582764\n",
      "Train 4 / 16 2.740264654159546\n",
      "Train 3 / 16 2.313530683517456\n",
      "Train 6 / 16 2.191023111343384\n",
      "Train 1 / 16 2.397824287414551\n",
      "Train 3 / 16 2.4146199226379395\n",
      "Train 4 / 16 2.677535057067871\n",
      "Train 4 / 16 2.591600179672241\n",
      "Train 8 / 16 2.629159927368164\n",
      "Train 7 / 16 2.4820852279663086\n",
      "Train 3 / 16 2.419776201248169\n",
      "Train 1 / 16 2.6705470085144043\n",
      "Train 6 / 16 2.5297882556915283\n",
      "Train 6 / 16 2.3238747119903564\n",
      "Train 6 / 16 2.3226490020751953\n",
      "Train 4 / 16 2.4615681171417236\n",
      "Train 2 / 16 2.252134323120117\n",
      "Train 3 / 16 2.2751035690307617\n",
      "Train 6 / 16 2.7816741466522217\n",
      "Train 4 / 16 2.43456768989563\n",
      "Train 6 / 16 2.5028185844421387\n",
      "Train 4 / 16 2.6744930744171143\n",
      "Train 1 / 16 2.7544620037078857\n",
      "Train 5 / 16 2.5724105834960938\n",
      "Train 3 / 16 2.324547529220581\n",
      "Train 6 / 16 2.215155839920044\n",
      "Train 3 / 16 2.8246545791625977\n",
      "Train 7 / 16 2.776946783065796\n",
      "Train 4 / 16 2.423771858215332\n",
      "Train 3 / 16 2.6962993144989014\n",
      "Train 2 / 16 2.1970314979553223\n",
      "Train 5 / 16 2.4979135990142822\n",
      "Train 3 / 16 2.622077226638794\n",
      "Train 4 / 16 2.4526870250701904\n",
      "Train 4 / 16 2.3176159858703613\n",
      "Train 5 / 16 2.169672966003418\n",
      "Train 10 / 16 2.4439170360565186\n",
      "Train 3 / 16 2.4692366123199463\n",
      "Train 3 / 16 2.470186710357666\n",
      "Train 3 / 16 2.640739917755127\n",
      "Train 2 / 16 2.9244930744171143\n",
      "Train 7 / 16 2.1608800888061523\n",
      "Train 2 / 16 2.386812448501587\n",
      "Train 5 / 16 2.5279834270477295\n",
      "Train 2 / 16 2.7002954483032227\n",
      "Train 2 / 16 2.4976694583892822\n",
      "Train 5 / 16 2.9794230461120605\n",
      "Train 2 / 16 2.587268114089966\n",
      "Train 0 / 16 2.2258145809173584\n",
      "Train 4 / 16 2.252070903778076\n",
      "Train 6 / 16 2.5662529468536377\n",
      "Train 7 / 16 2.524362325668335\n",
      "Train 7 / 16 2.110630989074707\n",
      "Train 5 / 16 2.553203582763672\n",
      "Train 2 / 16 2.697131633758545\n",
      "Train 5 / 16 2.5564000606536865\n",
      "Train 3 / 16 2.159585475921631\n",
      "Train 5 / 16 2.81481671333313\n",
      "Train 3 / 16 2.3556888103485107\n",
      "Train 1 / 16 2.4581992626190186\n",
      "Train 4 / 16 2.6738932132720947\n",
      "Train 4 / 16 2.382615804672241\n",
      "Train 4 / 16 2.1397671699523926\n",
      "Train 7 / 16 2.388700485229492\n",
      "Train 8 / 16 2.317166566848755\n",
      "Train 3 / 16 2.3515684604644775\n",
      "Train 3 / 16 2.587494373321533\n",
      "Train 3 / 16 2.3987481594085693\n",
      "Train 2 / 16 2.106677532196045\n",
      "Train 2 / 16 2.432340621948242\n",
      "Train 5 / 16 2.625253677368164\n",
      "Train 3 / 16 2.1671037673950195\n",
      "Train 3 / 16 2.720301866531372\n",
      "Train 6 / 16 3.2873518466949463\n",
      "Train 5 / 16 2.426150321960449\n",
      "Train 3 / 16 2.2436792850494385\n",
      "Train 2 / 16 1.8755567073822021\n",
      "Train 5 / 16 2.7485718727111816\n",
      "Train 3 / 16 2.5077292919158936\n",
      "Train 3 / 16 2.376493453979492\n",
      "Train 6 / 16 2.8921780586242676\n",
      "Train 5 / 16 2.4881367683410645\n",
      "Train 3 / 16 2.3546454906463623\n",
      "Train 4 / 16 2.911329746246338\n",
      "Train 5 / 16 2.0631189346313477\n",
      "Train 2 / 16 2.7204201221466064\n",
      "Train 1 / 16 3.0966854095458984\n",
      "Train 3 / 16 2.6713380813598633\n",
      "Train 6 / 16 2.367349624633789\n",
      "Train 5 / 16 2.327061653137207\n",
      "Train 4 / 16 2.0008156299591064\n",
      "Train 2 / 16 2.3592758178710938\n",
      "Train 2 / 16 2.3613147735595703\n",
      "Train 3 / 16 2.454786777496338\n",
      "Train 3 / 16 2.424109935760498\n",
      "Train 6 / 16 2.865983486175537\n",
      "Train 2 / 16 2.3337790966033936\n",
      "Train 5 / 16 2.486171245574951\n",
      "Train 3 / 16 2.191765546798706\n",
      "Train 4 / 16 2.512683629989624\n",
      "Train 6 / 16 2.777208089828491\n",
      "Train 5 / 16 2.6852171421051025\n",
      "Train 5 / 16 2.438433885574341\n",
      "Train 2 / 16 2.5839250087738037\n",
      "Train 6 / 16 2.435492515563965\n",
      "Train 8 / 16 2.694361448287964\n",
      "Train 3 / 16 2.3366024494171143\n",
      "Train 1 / 16 2.148623466491699\n",
      "Train 2 / 16 2.8664791584014893\n",
      "Train 1 / 16 2.496727705001831\n",
      "Train 2 / 16 2.370894432067871\n",
      "Train 4 / 16 2.27992582321167\n",
      "Train 2 / 16 1.9890211820602417\n",
      "Train 4 / 16 2.806046724319458\n",
      "Train 3 / 16 2.620530605316162\n",
      "Train 1 / 16 2.4035184383392334\n",
      "Train 4 / 16 2.1842141151428223\n",
      "Train 5 / 16 2.523300886154175\n",
      "Train 8 / 16 2.630511999130249\n",
      "Train 4 / 16 2.348667860031128\n",
      "Train 2 / 16 2.394727945327759\n",
      "Train 7 / 16 2.150735378265381\n",
      "Train 3 / 16 2.2573421001434326\n",
      "Train 3 / 16 3.011073589324951\n",
      "Train 6 / 16 2.8007495403289795\n",
      "Train 4 / 16 2.383241891860962\n",
      "Train 5 / 16 2.544826030731201\n",
      "Train 2 / 16 2.3540987968444824\n",
      "Train 4 / 16 2.455026865005493\n",
      "Train 1 / 16 2.5848166942596436\n",
      "Train 4 / 16 1.940346121788025\n",
      "Train 5 / 16 2.5131657123565674\n",
      "Train 3 / 16 2.3650221824645996\n",
      "Train 3 / 16 2.198927164077759\n",
      "Train 7 / 16 2.4636526107788086\n",
      "Train 4 / 16 2.71926212310791\n",
      "Train 3 / 16 2.5129282474517822\n",
      "Train 6 / 16 2.8766028881073\n",
      "Train 2 / 16 3.0460827350616455\n",
      "Train 4 / 16 2.5766804218292236\n",
      "Train 4 / 16 2.6042873859405518\n",
      "Train 4 / 16 2.26580548286438\n",
      "Train 3 / 16 1.8730263710021973\n",
      "Train 5 / 16 2.380312442779541\n",
      "Train 6 / 16 2.331210136413574\n",
      "Train 3 / 16 2.4038033485412598\n",
      "Train 2 / 16 2.3914403915405273\n",
      "Train 7 / 16 2.603505849838257\n",
      "Train 2 / 16 2.08927583694458\n",
      "Train 3 / 16 2.1008222103118896\n",
      "Train 4 / 16 2.2924954891204834\n",
      "Train 5 / 16 2.5072593688964844\n",
      "Train 6 / 16 2.762800931930542\n",
      "Train 3 / 16 2.202528953552246\n",
      "Train 3 / 16 2.716189384460449\n",
      "Train 8 / 16 2.414905071258545\n",
      "Train 2 / 16 2.541292905807495\n",
      "Train 3 / 16 2.629171848297119\n",
      "Train 4 / 16 2.57470703125\n",
      "Train 7 / 16 2.656545400619507\n",
      "Train 2 / 16 2.562387228012085\n",
      "Train 1 / 16 2.3250412940979004\n",
      "Train 0 / 16 2.743537425994873\n",
      "Train 3 / 16 2.1022279262542725\n",
      "Train 3 / 16 2.5143816471099854\n",
      "Train 4 / 16 2.505086898803711\n",
      "Train 4 / 16 2.2595884799957275\n",
      "Train 3 / 16 2.417954206466675\n",
      "Train 3 / 16 2.354672431945801\n",
      "Train 5 / 16 2.4127628803253174\n",
      "Train 2 / 16 2.1259522438049316\n",
      "Train 6 / 16 2.6461808681488037\n",
      "Train 4 / 16 2.180499315261841\n",
      "Train 3 / 16 2.3560218811035156\n",
      "Train 0 / 16 2.327712059020996\n",
      "Train 4 / 16 2.6002140045166016\n",
      "Train 3 / 16 2.4611387252807617\n",
      "Train 3 / 16 2.544393301010132\n",
      "Train 1 / 16 2.148514747619629\n",
      "Train 3 / 16 2.3988986015319824\n",
      "Train 3 / 16 2.624647617340088\n",
      "Train 3 / 16 2.308957099914551\n",
      "Train 4 / 16 2.7469065189361572\n",
      "Train 4 / 16 3.0522539615631104\n",
      "Train 3 / 16 2.5415396690368652\n",
      "Train 3 / 16 2.7318155765533447\n",
      "Train 4 / 16 2.430326223373413\n",
      "Train 4 / 16 2.313673973083496\n",
      "Train 1 / 16 1.970962643623352\n",
      "Train 5 / 16 2.608030080795288\n",
      "Train 4 / 16 2.7272369861602783\n",
      "Train 3 / 16 2.8033459186553955\n",
      "Train 2 / 16 2.723581314086914\n",
      "Train 8 / 16 2.4833898544311523\n",
      "Train 5 / 16 2.0194251537323\n",
      "Train 2 / 16 2.5734376907348633\n",
      "Train 3 / 16 2.3863613605499268\n",
      "Train 4 / 16 2.024913787841797\n",
      "Train 5 / 16 2.548541784286499\n",
      "Train 5 / 16 2.502335786819458\n",
      "Train 5 / 16 2.208618640899658\n",
      "Train 6 / 16 2.3719279766082764\n",
      "Train 4 / 16 2.167140007019043\n",
      "Train 2 / 16 2.5508787631988525\n",
      "Train 4 / 16 2.3681557178497314\n",
      "Train 3 / 16 2.5957348346710205\n",
      "Train 5 / 16 2.538243532180786\n",
      "Train 3 / 16 2.7907683849334717\n",
      "Train 2 / 16 2.654507637023926\n",
      "Train 3 / 16 2.3403728008270264\n",
      "Train 3 / 16 2.5854320526123047\n",
      "Train 3 / 16 2.26975154876709\n",
      "Train 7 / 16 2.6941816806793213\n",
      "Train 2 / 16 2.169680595397949\n",
      "Train 1 / 16 2.751023769378662\n",
      "Train 7 / 16 2.2913923263549805\n",
      "Train 8 / 16 2.6673314571380615\n",
      "Train 5 / 16 2.438469648361206\n",
      "Train 6 / 16 2.5501315593719482\n",
      "Train 5 / 16 2.202155113220215\n",
      "Train 6 / 16 2.5641894340515137\n",
      "Train 2 / 16 2.418447971343994\n",
      "Train 2 / 16 2.765590190887451\n",
      "Train 3 / 16 2.1788241863250732\n",
      "Train 4 / 16 2.5538604259490967\n",
      "Train 5 / 16 2.373897075653076\n",
      "Train 4 / 16 2.2388758659362793\n",
      "Train 5 / 16 2.408609628677368\n",
      "Train 2 / 16 2.2739686965942383\n",
      "Train 6 / 16 2.268341541290283\n",
      "Train 5 / 16 2.4853060245513916\n",
      "Train 4 / 16 2.1998093128204346\n",
      "Train 2 / 16 2.3599729537963867\n",
      "Train 4 / 16 2.4862587451934814\n",
      "Train 3 / 16 2.3818418979644775\n",
      "Train 2 / 16 2.315060615539551\n",
      "Train 2 / 16 2.351846694946289\n",
      "Train 3 / 16 3.0308070182800293\n",
      "Train 3 / 16 2.3649847507476807\n",
      "Train 2 / 16 2.3484318256378174\n",
      "Train 3 / 16 2.4142138957977295\n",
      "Train 0 / 16 1.9241478443145752\n",
      "Train 4 / 16 2.4646425247192383\n",
      "Train 4 / 16 2.461242437362671\n",
      "Train 4 / 16 2.0319135189056396\n",
      "Train 6 / 16 2.6967310905456543\n",
      "Train 5 / 16 2.504096269607544\n",
      "Train 6 / 16 2.616644859313965\n",
      "Train 4 / 16 2.6001038551330566\n",
      "Train 4 / 16 2.3867931365966797\n",
      "Train 6 / 16 2.126897096633911\n",
      "Train 1 / 16 2.113795042037964\n",
      "Train 3 / 16 2.75166916847229\n",
      "Train 3 / 16 2.819065570831299\n",
      "Train 6 / 16 2.115885019302368\n",
      "Train 4 / 16 2.1683404445648193\n",
      "Train 5 / 16 2.8462202548980713\n",
      "Train 8 / 16 1.8384126424789429\n",
      "Train 3 / 16 2.1181695461273193\n",
      "Train 3 / 16 2.265854597091675\n",
      "Train 6 / 16 2.2725114822387695\n",
      "Train 8 / 16 2.5073776245117188\n",
      "Train 4 / 16 2.2916057109832764\n",
      "Train 6 / 16 2.050077199935913\n",
      "Train 3 / 16 2.122379779815674\n",
      "Train 3 / 16 2.093705177307129\n",
      "Train 4 / 16 2.592005729675293\n",
      "Train 3 / 16 2.5141749382019043\n",
      "Train 3 / 16 3.0501222610473633\n",
      "Train 3 / 16 2.309774398803711\n",
      "Train 4 / 16 2.8274405002593994\n",
      "Train 5 / 16 2.7150790691375732\n",
      "Train 4 / 16 2.378936529159546\n",
      "Train 1 / 16 2.1635141372680664\n",
      "Train 5 / 16 2.3322346210479736\n",
      "Train 5 / 16 2.546617269515991\n",
      "Train 4 / 16 2.988485813140869\n",
      "Train 4 / 16 2.6699717044830322\n",
      "Train 5 / 16 2.2460169792175293\n",
      "Train 4 / 16 2.4790077209472656\n",
      "Train 4 / 16 2.5361626148223877\n",
      "Train 4 / 16 2.61771297454834\n",
      "Train 8 / 16 2.1308648586273193\n",
      "Train 5 / 16 2.8633439540863037\n",
      "Train 3 / 16 2.3609797954559326\n",
      "Train 8 / 16 2.0422747135162354\n",
      "Train 5 / 16 2.56001877784729\n",
      "Train 4 / 16 2.8710906505584717\n",
      "Train 6 / 16 2.57479190826416\n",
      "Train 4 / 16 2.404543876647949\n",
      "Train 6 / 16 2.1116702556610107\n",
      "Train 2 / 16 2.460249900817871\n",
      "Train 5 / 16 2.240791082382202\n",
      "Train 3 / 16 2.371420383453369\n",
      "Train 2 / 16 2.5142533779144287\n",
      "Train 5 / 16 2.709822654724121\n",
      "Train 6 / 16 2.162925958633423\n",
      "Train 7 / 16 2.2102932929992676\n",
      "Train 1 / 16 2.1409478187561035\n",
      "Train 4 / 16 2.4058408737182617\n",
      "Train 4 / 16 2.349332571029663\n",
      "Train 5 / 16 2.7306857109069824\n",
      "Train 7 / 16 1.7835383415222168\n",
      "Train 6 / 16 3.033435106277466\n",
      "Train 3 / 16 2.519688367843628\n",
      "Train 9 / 16 2.1531834602355957\n",
      "Train 6 / 16 2.1188735961914062\n",
      "Train 3 / 16 2.6139252185821533\n",
      "Train 7 / 16 2.646188974380493\n",
      "Train 2 / 16 2.3141157627105713\n",
      "Train 4 / 16 1.8918142318725586\n",
      "Train 3 / 16 1.9945580959320068\n",
      "Train 1 / 16 2.2239468097686768\n",
      "Train 3 / 16 2.5781285762786865\n",
      "Train 3 / 16 2.279006242752075\n",
      "Train 8 / 16 2.7815887928009033\n",
      "Train 3 / 16 2.44929838180542\n",
      "Train 6 / 16 2.1868789196014404\n",
      "Train 2 / 16 2.6105222702026367\n",
      "Train 3 / 16 2.7030365467071533\n",
      "Train 5 / 16 2.4829509258270264\n",
      "Train 6 / 16 1.7574549913406372\n",
      "Train 5 / 16 2.592240571975708\n",
      "Train 3 / 16 2.386758327484131\n",
      "Train 4 / 16 2.5052037239074707\n",
      "Train 7 / 16 2.32094407081604\n",
      "Train 3 / 16 2.5280280113220215\n",
      "Train 8 / 16 2.4726500511169434\n",
      "Train 2 / 16 2.4954733848571777\n",
      "Train 2 / 16 2.199739694595337\n",
      "Train 1 / 16 2.5123538970947266\n",
      "Train 3 / 16 2.332367181777954\n",
      "Train 4 / 16 2.3526217937469482\n",
      "Train 5 / 16 2.442939281463623\n",
      "Train 3 / 16 2.360487699508667\n",
      "Train 6 / 16 2.271650552749634\n",
      "Train 6 / 16 2.3684403896331787\n",
      "Train 4 / 16 1.9193469285964966\n",
      "Train 8 / 16 2.1368417739868164\n",
      "Train 4 / 16 2.5395169258117676\n",
      "Train 2 / 16 2.886124610900879\n",
      "Train 6 / 16 2.07521390914917\n",
      "Train 4 / 16 2.610157012939453\n",
      "Train 3 / 16 2.7181217670440674\n",
      "Train 6 / 16 2.5776572227478027\n",
      "Train 3 / 16 1.8768291473388672\n",
      "Train 6 / 16 2.2934281826019287\n",
      "Train 4 / 16 2.1060867309570312\n",
      "Train 5 / 16 2.154710531234741\n",
      "Train 6 / 16 2.247061014175415\n",
      "Train 7 / 16 1.9955123662948608\n",
      "Train 5 / 16 2.81406307220459\n",
      "Train 4 / 16 2.111018419265747\n",
      "Train 6 / 16 2.149040460586548\n",
      "Train 3 / 16 2.221421718597412\n",
      "Train 2 / 16 2.635681390762329\n",
      "Train 8 / 16 2.047478437423706\n",
      "Train 3 / 16 2.590953826904297\n",
      "Train 5 / 16 2.4292612075805664\n",
      "Train 4 / 16 2.329559564590454\n",
      "Train 1 / 16 2.4524118900299072\n",
      "Train 2 / 16 2.064352512359619\n",
      "Train 8 / 16 2.150134563446045\n",
      "Train 7 / 16 2.541654109954834\n",
      "Train 4 / 16 2.6380674839019775\n",
      "Train 2 / 16 2.592350721359253\n",
      "Train 1 / 16 2.236539363861084\n",
      "Train 3 / 16 2.28114914894104\n",
      "Train 4 / 16 2.7498230934143066\n",
      "Train 2 / 16 2.412616014480591\n",
      "Train 4 / 16 1.9159584045410156\n",
      "Train 4 / 16 2.780022382736206\n",
      "Train 2 / 16 2.2539424896240234\n",
      "Train 1 / 16 2.175827980041504\n",
      "Train 4 / 16 2.175098419189453\n",
      "Train 2 / 16 2.5052406787872314\n",
      "Train 5 / 16 2.335157871246338\n",
      "Train 5 / 16 2.4650375843048096\n",
      "Train 2 / 16 2.629188299179077\n",
      "Train 6 / 16 2.3651013374328613\n",
      "Train 4 / 16 2.42110013961792\n",
      "Train 4 / 16 2.1796631813049316\n",
      "Train 4 / 16 2.5023348331451416\n",
      "Train 8 / 16 2.554405689239502\n",
      "Train 4 / 16 2.4846572875976562\n",
      "Train 3 / 16 2.708019256591797\n",
      "Train 8 / 16 2.3568198680877686\n",
      "Train 2 / 16 2.504382371902466\n",
      "Train 5 / 16 2.428281307220459\n",
      "Train 3 / 16 2.4327821731567383\n",
      "Train 6 / 16 2.516918659210205\n",
      "Train 6 / 16 2.3444511890411377\n",
      "Train 2 / 16 2.3370707035064697\n",
      "Train 6 / 16 2.223358392715454\n",
      "Train 2 / 16 2.449784755706787\n",
      "Train 5 / 16 2.099351644515991\n",
      "Train 3 / 16 2.4492218494415283\n",
      "Train 3 / 16 2.544205665588379\n",
      "Train 4 / 16 2.1723709106445312\n",
      "Train 3 / 16 2.043233871459961\n",
      "Train 2 / 16 2.740908622741699\n",
      "Train 4 / 16 2.4765777587890625\n",
      "Train 2 / 16 2.3960013389587402\n",
      "Train 1 / 16 2.3358662128448486\n",
      "Train 4 / 16 2.6439647674560547\n",
      "Train 7 / 16 2.3564507961273193\n",
      "Train 4 / 16 2.479189395904541\n",
      "Train 3 / 16 2.6716723442077637\n",
      "Train 4 / 16 1.8491730690002441\n",
      "Train 4 / 16 2.1261839866638184\n",
      "Train 7 / 16 2.6845412254333496\n",
      "Train 5 / 16 2.9787678718566895\n",
      "Train 4 / 16 2.390174150466919\n",
      "Train 3 / 16 2.255960464477539\n",
      "Train 3 / 16 2.1025822162628174\n",
      "Train 5 / 16 2.3952693939208984\n",
      "Train 3 / 16 2.828216552734375\n",
      "Train 1 / 16 2.3188655376434326\n",
      "Train 3 / 16 2.164766311645508\n",
      "Train 4 / 16 2.2293379306793213\n",
      "Train 1 / 16 2.307861804962158\n",
      "Train 3 / 16 2.2614681720733643\n",
      "Train 5 / 16 2.0940403938293457\n",
      "Train 4 / 16 2.5145363807678223\n",
      "Train 3 / 16 2.375521183013916\n",
      "Train 5 / 16 1.9032974243164062\n",
      "Train 6 / 16 2.4988439083099365\n",
      "Train 2 / 16 2.5144033432006836\n",
      "Train 4 / 16 2.55645751953125\n",
      "Train 3 / 16 2.173790216445923\n",
      "Train 3 / 16 1.9683905839920044\n",
      "Train 3 / 16 2.106645107269287\n",
      "Train 3 / 16 2.282132148742676\n",
      "Train 5 / 16 2.075901508331299\n",
      "Train 2 / 16 2.7266323566436768\n",
      "Train 3 / 16 2.4055185317993164\n",
      "Train 3 / 16 2.481433629989624\n",
      "Train 3 / 16 2.4582035541534424\n",
      "Train 4 / 16 2.486760139465332\n",
      "Train 4 / 16 2.2769973278045654\n",
      "Train 5 / 16 2.338841438293457\n",
      "Train 3 / 16 2.9800057411193848\n",
      "Train 7 / 16 2.7884202003479004\n",
      "Train 5 / 16 2.2985546588897705\n",
      "Train 3 / 16 2.032216787338257\n",
      "Train 7 / 16 2.4913651943206787\n",
      "Train 8 / 16 2.3450047969818115\n",
      "Train 4 / 16 2.36501407623291\n",
      "Train 3 / 16 2.32289719581604\n",
      "Train 4 / 16 2.0505032539367676\n",
      "Train 4 / 16 2.9566490650177\n",
      "Train 7 / 16 1.975818395614624\n",
      "Train 5 / 16 2.2919418811798096\n",
      "Train 5 / 16 2.3922901153564453\n",
      "Train 5 / 16 2.564502239227295\n",
      "Train 4 / 16 2.2077722549438477\n",
      "Train 5 / 16 2.106912851333618\n",
      "Train 3 / 16 2.3004422187805176\n",
      "Train 6 / 16 2.5765836238861084\n",
      "Train 6 / 16 2.254532814025879\n",
      "Train 3 / 16 2.1999399662017822\n",
      "Train 5 / 16 2.883427858352661\n",
      "Train 3 / 16 2.531924247741699\n",
      "Train 7 / 16 2.5424540042877197\n",
      "Train 4 / 16 2.7125608921051025\n",
      "Train 4 / 16 2.7202279567718506\n"
     ]
    }
   ],
   "source": [
    "weight_decay = 1e-1\n",
    "beta1 = 0.9\n",
    "beta2 = 0.999\n",
    "learning_rate = 5e-4 # max learning rate\n",
    "device_type = 'cpu'\n",
    "epochs = 1\n",
    "optimizer = model.configure_optimizers(weight_decay, learning_rate, (beta1, beta2), device_type)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # TRAIN\n",
    "    print(\"Training Epoch\", epoch)\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        X = batch['input_ids'][:, :-1]\n",
    "        Y = batch['input_ids'][:, 1:]\n",
    "        \n",
    "        noop_dense = torch.zeros((X.shape[0], X.shape[1], model.config.n_embd))\n",
    "\n",
    "        logits, dense, loss = model(X, noop_dense, Y)\n",
    "        \n",
    "        print('Train', get_accuracy(Y, batch['label_index'], logits), \"/\", X.shape[0], loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    # VALIDATE\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch in val_dataloader:\n",
    "        X = batch['input_ids'][:, :-1]\n",
    "        Y = batch['input_ids'][:, 1:]\n",
    "        \n",
    "        # check if Y is contiguous        \n",
    "        noop_dense = torch.zeros((X.shape[0], X.shape[1], model.config.n_embd))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits, dense, loss = model(X, noop_dense, Y)\n",
    "            \n",
    "            total += X.shape[0]\n",
    "            correct += get_accuracy(Y, batch['label_index'], logits, doPrint=(epoch == epochs-1))\n",
    "            \n",
    "    print(\"Validation Accuracy:\", correct, \"/\", total, \"=\", correct/total)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b66dbdb614bfd022b649975f993762ad232399f75e8f30cb9176d485ed5b8487"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
