{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Engineering for Dense Tokens 2.0\n",
    "\n",
    "1. Convert model to non-causal decoder\n",
    "\n",
    "Create attention mask using a combination of `self.bias` param already used in CasusalSelfAttention, and potentially an input param that dictates the number of tokens to allow full attention for.\n",
    "\n",
    "To my understanding, torch.nn.functional.scaled_dot_product_attention should accept this mask as input happily, we just need to pass `is_casual=False`.\n",
    "\n",
    "2. Pre-train the model with in a non-causal decoder setting\n",
    "\n",
    "Run some number of training steps to set the model up to a good starting point. Need to generate the mask for the non-causal decoder, and additionally only calculate loss for the causual tokens.\n",
    "\n",
    "Probably don't need to do the other U-Flan training objectives.\n",
    "\n",
    "(EXPERIMENT: Compare Casual inference, PrefixModel inference and Non-Casual inference -> expect perf gain at each stage)\n",
    "\n",
    "3. Dense token training\n",
    "\n",
    "First, need to figure out how training RNNs works in PyTorch. \n",
    "Additionally, figure out the steps involved in meshing 'non-casual' with 'RNN' stuff.\n",
    "\n",
    "4. Run evaluations and stuff.\n",
    "\n",
    "Need to build or find an evaluation framework to actually give each model a fair comparision.\n",
    "\n",
    "--\n",
    "\n",
    "Problems: \n",
    "- Compute access to train the model\n",
    "    - How much should I dedicate to this experiment?\n",
    "- Benchmarks that the model can actually pass\n",
    "    - Have had trouble getting the model to pass the benchmarks in the past\n",
    "- RNN details\n",
    "    - Some finicky stuff here, let's think more.\n",
    "\n",
    "\n",
    "1)\n",
    "1.63AUD per hour for 1 GPU\n",
    "\n",
    "I'm spending approx $15/h in my time, and easily 15 sessions worth of time to get this working.\n",
    "Let's say training budget of $300 AUD to start with = 180 A100 GPU hours.\n",
    "\n",
    "\n",
    "2) I've tried a variety of benchmarks previously and yet to have any sub-1B model pass them. Do I need to train something large like 1B plus to get a good result and actually test the hypothesis?\n",
    "\n",
    "---\n",
    "\n",
    "One issue I don't like is how much this architecture deviates from standard GPT. It'd be much nicer if it was just a slighly variation.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Ok, If I had good benchmarks to start with then I'd know what i'm doing. Let's go find Pythia benchmarks and see if that helps.\n",
    "DONE\n",
    "\n",
    "- piqa\n",
    "- sciq\n",
    "- arc_easy\n",
    "\n",
    "All should supposedly work in zero shot mode, so I can use them to test the model easily while pre-training...\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps then:\n",
    "\n",
    "1. Build quick evaluation framework to test models during training.\n",
    "2. Find a dataset to use for pre-training.\n",
    "3. Convert the model to non-casual decoder.\n",
    "4. Setup training script, with logging, checkpoint saving and evaluation.\n",
    "5. Train the model for 10 hours and see how it goes.\n",
    "\n",
    "---\n",
    "\n",
    "QUESTION TO ANSWER: Will I be able to replicate UL2 with only then non-casual decoder?\n",
    "Let's aim to do all this today, and start the training run tomorrow!\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
